{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Density Estimation of Subjective Distribution of Income Growth\n",
    "\n",
    "- Following Manski et al.(2009)\n",
    "- Depending on the locations and number of bins, there are three cases \n",
    "   - case 1. 3+ intervales with positive probabilities, to be fitted with a generalized beta distribution\n",
    "   - case 2. exactly 2 adjacent intervals with positive probabilities, to be fitted with a triangle distribution \n",
    "   - case 3. one interval only, to be fitted with a uniform distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import gamma\n",
    "from scipy.stats import beta \n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import minimize\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 1. Generalized Beta Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def GeneralizedBetaEst(bin,\n",
    "                       probs,\n",
    "                       rep = 3):\n",
    "    \"\"\"\n",
    "    This fits a histogram with positive probabilities in at least 3 bins to a generalized beta distribution.\n",
    "    Depending on if there is open-ended bin on either side with positive probability, \n",
    "       the estimator decides to estimate 2 or 4 parameters, respectively. \n",
    "       \n",
    "    paramters\n",
    "    ---------\n",
    "    bin:  ndarray, (n+1) x 1 \n",
    "          positions for n bins in the histograms \n",
    "          \n",
    "    probs:  ndarrray n x 1\n",
    "          each entry is a probability for each of the n bins given by the surveyee, between 0 and 1\n",
    "                 \n",
    "    returns\n",
    "    -------\n",
    "    moments:  ndarray of 2 or 4  \n",
    "              2:  alpha and beta \n",
    "              4:  alpha, beta, lb, ub, e.g. lb=0 and ub=1 for a standard beta distribution\n",
    "    \"\"\"\n",
    "    # n+1 bins and n probs, both are arrays\n",
    "    if sum([probs[i] > 0 for i in range(len(bin)-1)])<3:\n",
    "        print(\"Warning: at least three bins with positive probs are needed\")\n",
    "        para_est = None\n",
    "    if sum(probs) != 1:\n",
    "        print(\"probs need to sum up to 1\")\n",
    "        para_est = None\n",
    "    else:\n",
    "        cdf = np.cumsum(probs)\n",
    "        pprob = [i for i in range(len(bin)-1) if probs[i]>0]\n",
    "        lb = bin[min(pprob)]\n",
    "        print(\"lower bound is \"+str(lb))\n",
    "        ub = bin[max(pprob)+1]\n",
    "        print(\"upper bound is \"+str(ub))\n",
    "        x0_2para = (2,1)\n",
    "        x0_4para = (2,1,0,1) \n",
    "        def distance2para(paras2): # if there is no open-ended bin with positive probs \n",
    "            a,b = paras2\n",
    "            distance = sum((beta.cdf(bin[1:],a,b,loc=lb,scale=ub-lb)-cdf)**2)\n",
    "            return distance\n",
    "        def distance4para(paras4): # if either on the left or right side one open-ended bin is with postive probs\n",
    "            a,b,lb,ub = paras4\n",
    "            distance = sum((beta.cdf(bin[1:],a,b,loc=lb,scale=ub-lb)-cdf)**2)\n",
    "            return distance\n",
    "        \n",
    "        ## 4-parameter estimation\n",
    "        if lb == bin[0] and ub == bin[-1]:\n",
    "            para_est_holder = np.zeros(4)\n",
    "            suc_ct = 0\n",
    "            for time in range(rep):\n",
    "                para_est_rs = minimize(distance4para,\n",
    "                                    x0_4para,\n",
    "                                    method='CG',\n",
    "                                    options={'disp':True,\n",
    "                                             'gtol': 1e-06})\n",
    "                para_est = para_est_rs['x']\n",
    "                print(para_est_rs)\n",
    "                if not np.isnan(para_est).any():\n",
    "                    suc_ct = suc_ct+1  ## only counts the times of success to divide for avearge \n",
    "                para_est_holder = para_est_holder + para_est         \n",
    "            para_est = para_est_holder/suc_ct \n",
    "            \n",
    "        ## 2-parameter estimation\n",
    "        else:\n",
    "            para_est_holder = np.zeros(2)\n",
    "            suc_ct = 0\n",
    "            for time in range(rep):\n",
    "                para_est_rs = minimize(distance2para,\n",
    "                                    x0_2para,\n",
    "                                    method='CG',\n",
    "                                    options={'disp':True,\n",
    "                                             'gtol': 1e-06})\n",
    "                para_est = para_est_rs['x']\n",
    "                print(para_est_rs)\n",
    "                if not np.isnan(para_est).any(): ## if para_est is not null \n",
    "                    suc_ct = suc_ct+1  ## only counts the times of success to divide for avearge \n",
    "                para_est_holder = para_est_holder + para_est\n",
    "            para_est = para_est_holder/suc_ct\n",
    "        return para_est   # could be 2 or 4 parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def GeneralizedBetaStats(a,b,lb,ub):\n",
    "    \"\"\"\n",
    "    This function computes the moments of a generalized beta distribution, mean and variance for now. \n",
    "    \n",
    "    parameters\n",
    "    ----------\n",
    "    a, b, lb, ub: floats\n",
    "    \n",
    "    returns\n",
    "    -------\n",
    "    dict:  4 keys\n",
    "           mean, float \n",
    "           variance, float\n",
    "           skewness,float\n",
    "           kurtosis,float\n",
    "    \"\"\"\n",
    "    # lb=0 and ub=1 for a standard beta distribution\n",
    "    \n",
    "    mean, var, skew, kurt = beta.stats(a, b, loc=lb, scale=ub-lb, moments='mvsk')\n",
    "    #mean = lb + (ub-lb)*a/(a+b)\n",
    "    #var = (ub-lb)**2*a*b/((a+b)**2*(a+b+1))\n",
    "    return {\"mean\": mean,\n",
    "            \"variance\":var,\n",
    "            \"skewness\":skew,\n",
    "            \"kurtosis\":kurt}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 2. Isosceles Triangle distribution\n",
    "\n",
    "Two adjacent intervales $[a,b]$,$[b,c]$ are assigned probs $\\alpha$ and $1-\\alpha$, respectively. In the case of $\\alpha<1/2$, we need to solve parameter $t$ such that $[b-t,c]$ is the interval of the distribution. Denote the height of the trangle distribution $h$. Then following two restrictions need to satisfy\n",
    "\n",
    "\\begin{eqnarray}\n",
    "\\frac{t^2}{t+c-b} h = \\alpha \\\\\n",
    "(t+(c-b))h = 2\n",
    "\\end{eqnarray}\n",
    "\n",
    "The two equations can solve $t$ and $h$\n",
    "\n",
    "$$\\frac{t^2}{(t+c-b)^2}=\\alpha$$\n",
    "\n",
    "$$t^2 = \\alpha t^2 + 2\\alpha t(c-b) + \\alpha(c-b)^2$$\n",
    "\n",
    "$$(1-\\alpha) t^2 - 2\\alpha(c-b) t - \\alpha(c-b)^2=0$$\n",
    "\n",
    "$$\\implies t =\\frac{2\\alpha(c-b)+\\sqrt{4\\alpha^2(c-b)^2+4(1-\\alpha)\\alpha(c-b)^2}}{2(1-\\alpha)} = \\frac{\\alpha(c-b)+(c-b)\\sqrt{\\alpha}}{(1-\\alpha)}$$\n",
    "\n",
    "$$\\implies h = \\frac{2}{t+c-b}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def TriangleEst(bin,probs):\n",
    "    \"\"\"\n",
    "    The function fits histograms with exactly two adjacent \n",
    "       bins of positive probabilitie to a isosceles triangular distribution.\n",
    "    It genetes the bounds of the isoceles triangle distribution. \n",
    "    \n",
    "    paramters\n",
    "    ---------\n",
    "    bin:  ndarray, (n+1) x 1 \n",
    "          positions for n bins in the histograms \n",
    "          \n",
    "    probs:  ndarrray n x 1\n",
    "          each entry is a probability for each of the n bins given by the surveyee, between 0 and 1\n",
    "    \n",
    "    returns\n",
    "    --------\n",
    "    dict: 3 keys\n",
    "          lb: float, left bound \n",
    "          ub: float, right bound\n",
    "          h:  float, height of the triangle\n",
    "    \n",
    "    \"\"\"\n",
    "    if sum([probs[i]>0 for i in range(len(bin)-1)])==2:\n",
    "        print(\"There are two bins with positive probs\")\n",
    "        pprobadj = [i for i in range(1,len(bin)-3) if probs[i]>0 and probs[i+1]>0]   # from 1 to -3 bcz excluding the open-ended on the left/right\n",
    "        if sum(pprobadj)>0:\n",
    "            print('The two intervals are adjacent and not open-ended')\n",
    "            min_i = min(pprobadj)\n",
    "            #print(min_i)\n",
    "            #print(probs[min_i])\n",
    "            #print(probs[min_i+1])\n",
    "            #print(pprobadj[0])\n",
    "            #print(pprobadj[0]+2)\n",
    "            #print(probs[min_i] > probs[min_i+1])\n",
    "            #print(bin[pprobadj[0]])\n",
    "            #print(bin[pprobadj[0]+2])\n",
    "            if probs[min_i] > probs[min_i+1]:\n",
    "                alf = probs[min_i+1]\n",
    "                lb = bin[pprobadj[0]]\n",
    "                scl = bin[pprobadj[0]+1]-bin[pprobadj[0]]\n",
    "                t = scl*(alf/(1-alf) +np.sqrt(alf)/(1-alf))\n",
    "                ub = bin[pprobadj[0]+1]+t \n",
    "                h = 2/(t+bin[pprobadj[0]+1]-bin[pprobadj[0]])\n",
    "            if probs[min_i] < probs[min_i+1]:\n",
    "                alf = probs[min_i]\n",
    "                ub = bin[pprobadj[0]+2]\n",
    "                scl = bin[pprobadj[0]+2]-bin[pprobadj[0]+1]\n",
    "                t = scl*(alf/(1-alf) + np.sqrt(alf)/(1-alf))\n",
    "                lb = bin[pprobadj[0]+1]-t  \n",
    "                h = 2/(t+bin[pprobadj[0]+2]-bin[pprobadj[0]+1])\n",
    "            if probs[min_i] == probs[min_i+1]:\n",
    "                ub=bin[pprobadj[0]]\n",
    "                lb=bin[pprobadj[0]+2]\n",
    "                h = 2/(ub-lb)\n",
    "        else:\n",
    "            lb = np.nan\n",
    "            ub = np.nan\n",
    "            h = np.nan\n",
    "            print('Warning: the two intervals are not adjacent or are open-ended')\n",
    "    return {'lb':lb,'ub':ub,\"height\":h}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pdf of a triangle distribution\n",
    "\n",
    "\\begin{eqnarray}\n",
    "f(x)= & 1/2(x-lb) \\frac{x-lb}{(ub+lb)/2}h \\quad \\text{if } x <(lb+ub)/2 \\\\\n",
    "& = 1/2(ub-x) \\frac{ub-x}{(ub+lb)/2}h \\quad \\text{if } x \\geq(lb+ub)/2\n",
    "\\end{eqnarray}\n",
    "\n",
    "\\begin{eqnarray}\n",
    "& Var(x) & = \\int^{ub}_{lb} (x-(lb+ub)/2)^2 f(x) dx \\\\\n",
    "& & = 2 \\int^{(ub+lb)/2}_{lb} (x-(lb+ub)/2)^2 (x-lb) \\frac{x-lb}{(ub+lb)/2}h dx\n",
    "\\end{eqnarray}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def TriangleStats(lb,ub):\n",
    "    \"\"\"\n",
    "    parameters\n",
    "    ----------\n",
    "    lb and ub:  float, left and right bounds of the triangle distribution\n",
    "    \n",
    "    returns\n",
    "    -------\n",
    "    dict:  2 keys for now\n",
    "           mean: estimated mean\n",
    "           variance: estimated variance\n",
    "    \"\"\"\n",
    "    \n",
    "    mean = (lb+ub)/2\n",
    "    var = (lb**2+ub**2+(lb+ub)**2/4-lb*(lb+ub)/2-ub*(lb+ub)/2-lb*ub)/18\n",
    "    skew = 0\n",
    "    kurt = -3/5\n",
    "    return {\"mean\":mean,\n",
    "            \"variance\":var,\n",
    "            'skewness':skew,\n",
    "            'kurtosis':kurt}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 3. Uniform Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def UniformEst(bin,probs):\n",
    "    \"\"\"\n",
    "    This function fits a histogram with only one bin of positive probability to a uniform distribution.\n",
    "    \n",
    "    paramters\n",
    "    ---------\n",
    "    bin:  ndarray, (n+1) x 1 \n",
    "          positions for n bins in the histograms \n",
    "          \n",
    "    probs:  ndarrray n x 1\n",
    "          each entry is a probability for each of the n bins given by the surveyee, between 0 and 1\n",
    "    \n",
    "    returns\n",
    "    --------\n",
    "    dict: 2 keys\n",
    "          lb and ub, float. the left and right bounds of the uniform distribution\n",
    "    \"\"\"\n",
    "    pprob=[i for i in range(len(bin)-1) if probs[i]>0]\n",
    "    if len(pprob)==1:\n",
    "        if pprob[0]!=0 and pprob[0]!=len(bin)-1:\n",
    "            lb = bin[pprob[0]]\n",
    "            ub = bin[pprob[0]+1]\n",
    "        else:\n",
    "            lb = np.nan\n",
    "            ub = np.nan\n",
    "    else:\n",
    "        lb = np.nan\n",
    "        ub = np.nan\n",
    "    return {\"lb\":lb,\"ub\":ub}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def UniformStats(lb,ub):\n",
    "    \"\"\"\n",
    "    The function computes the moment of a uniform distribution.\n",
    "    \n",
    "    parameters\n",
    "    ----------\n",
    "    lb and ub, floats, left and right bounds of uniform distribution\n",
    "    \n",
    "    returns\n",
    "    --------\n",
    "    dict:  2 keys for now\n",
    "           mean: estimated mean\n",
    "           variance: estimated variance \n",
    "    \"\"\"\n",
    "    \n",
    "    if lb.size>0 and ub.size>0:\n",
    "        print(\"yes\")\n",
    "        mean = (lb+ub)/2\n",
    "        var = (ub-lb)**2/12\n",
    "        skew = 0\n",
    "        kurt = -5/6\n",
    "    else:\n",
    "        mean = np.nan\n",
    "        var = np.nan\n",
    "        skew = np.nan\n",
    "        kurt = np.nan\n",
    "    return {\"mean\":mean,\n",
    "            \"variance\":var,\n",
    "           \"skewness\":skew,\n",
    "           \"kurtosis\":kurt}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test using made-up data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "## test 1: GenBeta Dist\n",
    "#sim_bins= np.array([0,0.2,0.32,0.5,1,1.3])\n",
    "#sim_probs=np.array([0,0.2,0.5,0.3,0])\n",
    "#sim_para = GeneralizedBetaEst(sim_bins,sim_probs)\n",
    "#GeneralizedBetaStats(sim_para[0],sim_para[1],0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "## test 2: Triangle Dist\n",
    "#sim_bins2 = np.array([0,0.2,0.32,0.5,1,1.2])\n",
    "#sim_probs2=np.array([0.2,0,0.8,0,0])\n",
    "#TriangleEst(sim_bins2,sim_probs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "## test 3: Uniform Dist\n",
    "\n",
    "#sim_bins3 = np.array([0,0.2,0.32,0.5,1,1.2])\n",
    "#sim_probs3=np.array([0,0,0,0,1])\n",
    "#sim_para3 = UniformEst(sim_bins3,sim_probs3)\n",
    "#UniformStats(sim_para3['lb'],sim_para3['ub'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test with simulated data from known distribution \n",
    "- we simulate data from a true beta distribution with known parameters\n",
    "- then we estimate the parameters with our module and see how close it is with the true parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "## simulate a generalized distribution\n",
    "#sim_n=50\n",
    "#true_alpha,true_beta,true_loc,true_scale=1.4,2.2,0,1\n",
    "#sim_data = beta.rvs(true_alpha,true_beta,loc=true_loc,scale=true_scale,size=sim_n)\n",
    "#sim_bins2=plt.hist(sim_data)[1]\n",
    "#sim_probs2=plt.hist(sim_data)[0]/sim_n\n",
    "#sim_est=GeneralizedBetaEst(sim_bins2,sim_probs2)\n",
    "#sim_est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "## plot the estimated generalized beta versus the histogram of simulated data drawn from a true beta distribution \n",
    "#sim_x = np.linspace(true_loc,true_loc+true_scale,sim_n)\n",
    "#sim_pdf=beta.pdf(sim_x,sim_est[0],sim_est[1],loc=true_loc,scale=true_scale)\n",
    "#plt.plot(sim_x,sim_pdf,label='Estimated pdf')\n",
    "#plt.hist(sim_data,density=True,label='Dist of Simulated Data')\n",
    "#plt.legend(loc=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "## This is the synthesized density estimation function\n",
    "def SynDensityStat(bin,\n",
    "                   probs):\n",
    "    \"\"\"\n",
    "    Synthesized density estimate module:\n",
    "    It first detects the shape of histograms\n",
    "    Then accordingly invoke the distribution-specific tool.\n",
    "    \n",
    "    paramters\n",
    "    ---------\n",
    "    bin:  ndarray, (n+1) x 1 \n",
    "          positions for n bins in the histograms \n",
    "          \n",
    "    probs:  ndarrray n x 1\n",
    "          each entry is a probability for each of the n bins given by the surveyee, between 0 and 1\n",
    "    \n",
    "    returns\n",
    "    -------\n",
    "    moments: dict with 2 keys (more to be added in future)\n",
    "            mean: empty or float, estimated mean \n",
    "            variance:  empty or float, estimated variance \n",
    "            skewness:  empty or float, estimated skewness \n",
    "            kurtosis:  empty or float, estimated kurtosis\n",
    "    \n",
    "    \"\"\"\n",
    "    if sum(probs)==1:\n",
    "        print(\"probs sum up to 1\")\n",
    "        ## Beta distributions \n",
    "        if sum([probs[i]>0 for i in range(len(bin)-1)])>=3:\n",
    "            print(\"at least three bins with positive probs\")\n",
    "            para_est=GeneralizedBetaEst(bin,probs)\n",
    "            if len(para_est)==4:\n",
    "                print('4 parameters')\n",
    "                return GeneralizedBetaStats(para_est[0],para_est[1],para_est[2],para_est[3])\n",
    "            if len(para_est)==2:\n",
    "                print('2 parameters')\n",
    "                return GeneralizedBetaStats(para_est[0],para_est[1],0,1)\n",
    "        ## Triangle distributions\n",
    "        if sum([probs[i]>0 for i in range(len(bin)-1)])==2:\n",
    "            #print(\"There are two bins with positive probs\")\n",
    "            pprobadj = [i for i in range(1,len(bin)-3) if probs[i]>0 and probs[i+1]>0]   # from 1 to -3 bcz excluding the open-ended on the left/right\n",
    "            if sum(pprobadj)>0:\n",
    "                #print('The two intervals are adjacent and not open-ended')\n",
    "                para_est=TriangleEst(bin,probs)\n",
    "                return TriangleStats(para_est['lb'],para_est['ub'])\n",
    "        if sum([probs[i]>0 for i in range(len(bin)-1)])==1:\n",
    "            print('Only one interval with positive probs')\n",
    "            para_est= UniformEst(bin,probs)\n",
    "            print(para_est)\n",
    "            return UniformStats(para_est['lb'],para_est['ub'])\n",
    "        else:\n",
    "            return {\"mean\":None,\n",
    "                    \"variance\":None,\n",
    "                    \"skewness\":None,\n",
    "                    \"kurtosis\":None}\n",
    "    else:\n",
    "        return {\"mean\":np.nan,\n",
    "                \"variance\":np.nan,\n",
    "                \"skewness\":np.nan,\n",
    "                \"kurtosis\":np.nan}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "## testing the synthesized estimator function using an arbitrary example created above\n",
    "#SynDensityStat(sim_bins3,sim_probs3)['mean']"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_json": true,
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
